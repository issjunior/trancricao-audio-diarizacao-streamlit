import os
import traceback
import streamlit as st
from dotenv import load_dotenv
import whisper
from pyannote.audio import Pipeline
from docx import Document
import pandas as pd
from io import BytesIO
import queue
import multiprocessing
import psutil
from datetime import timedelta

# üñ•Ô∏è Configura√ß√£o da p√°gina
st.set_page_config(layout="wide", page_title="SPAV - Transcri√ß√£o", page_icon="üéôÔ∏è")
os.environ["SPEECHBRAIN_LOCAL_CACHE_STRATEGY"] = "copy"

# üíª Configura√ß√µes de otimiza√ß√£o
num_cores = multiprocessing.cpu_count()
mem_total_gb = psutil.virtual_memory().total / (1024 ** 3)
disk = psutil.disk_usage("/")
total_gb = disk.total / (1024 ** 3)
used_gb = disk.used / (1024 ** 3)
free_gb = disk.free / (1024 ** 3)

# Usa sempre todos os n√∫cleos dispon√≠veis
threads = num_cores

# Aplica as configura√ß√µes de threads
os.environ["OMP_NUM_THREADS"] = str(threads)
os.environ["MKL_NUM_THREADS"] = str(threads)
os.environ["NUMEXPR_NUM_THREADS"] = str(threads)

# üîß Inicializa√ß√£o das configura√ß√µes de sess√£o
if 'habilitar_diarizacao' not in st.session_state:
    st.session_state['habilitar_diarizacao'] = True
if 'chunk_processing' not in st.session_state:
    st.session_state['chunk_processing'] = True
if 'auto_cleanup' not in st.session_state:
    st.session_state['auto_cleanup'] = True

# üï∞Ô∏è Fun√ß√£o para criar SRT
def criar_srt(falas):
    srt_content = []
    for i, fala in enumerate(falas, 1):
        minutos_inicio, segundos_inicio = map(int, fala["tempo"].split(" - ")[0].split(":"))
        minutos_fim, segundos_fim = map(int, fala["tempo"].split(" - ")[1].split(":"))
        
        tempo_inicio = timedelta(minutes=minutos_inicio, seconds=segundos_inicio)
        tempo_fim = timedelta(minutes=minutos_fim, seconds=segundos_fim)
        
        srt_timestamp_inicio = str(tempo_inicio).replace(".", ",")[:12]
        srt_timestamp_fim = str(tempo_fim).replace(".", ",")[:12]
        
        srt_texto = f"{fala['locutor']}: {fala['texto'].strip('\"')}"
        
        srt_entry = (
            f"{i}\n"
            f"{srt_timestamp_inicio} --> {srt_timestamp_fim}\n"
            f"{srt_texto}\n\n"
        )
        srt_content.append(srt_entry)
    
    return "".join(srt_content)

# üõ†Ô∏è Fun√ß√µes auxiliares
def formatar_tempo(tempo_em_segundos):
    minutos = int(tempo_em_segundos // 60)
    segundos = int(tempo_em_segundos % 60)
    return f"{minutos:02}:{segundos:02}"

def atualizar_progresso(progresso_bar, status_text, etapa, valor, detalhes=""):
    status_msg = f"{etapa}"
    if detalhes:
        status_msg += f" - {detalhes}"
    status_text.text(status_msg)
    progresso_bar.progress(int(min(valor, 100)))

def processar_audio_chunk(modelo, audio_path, language, progress_queue):
    try:
        lang_param = None if language == "auto" else language
        resultado = modelo.transcribe(
            audio_path,
            language=lang_param,
            verbose=False,
            fp16=False,
            temperature=0.0
        )
        progress_queue.put(("transcricao_completa", resultado))
    except Exception as e:
        progress_queue.put(("erro", str(e)))

def processar_diarizacao(audio_path, token, progress_queue):
    try:
        pipeline = Pipeline.from_pretrained(
            "pyannote/speaker-diarization",
            use_auth_token=token
        )
        diarization = pipeline(audio_path)
        progress_queue.put(("diarizacao_completa", diarization))
    except Exception as e:
        progress_queue.put(("erro", str(e)))

# üéõÔ∏è Configura√ß√£o da barra lateral
opcoes_modelos = {
    "tiny": {"nome": "Tiny", "descricao": "Ultra r√°pido, baixa precis√£o", "tamanho": "39MB"},
    "base": {"nome": "Base", "descricao": "R√°pido, precis√£o moderada", "tamanho": "74MB"},
    "small": {"nome": "Small", "descricao": "Balanceado", "tamanho": "244MB"},
    "medium": {"nome": "Medium", "descricao": "Mais lento, boa precis√£o", "tamanho": "769MB"},
    "large": {"nome": "Large", "descricao": "Muito lento, alta precis√£o", "tamanho": "1.5GB"},
    "large-v2": {"nome": "Large-v2", "descricao": "Vers√£o 2 do modelo Large, melhor precis√£o", "tamanho": "1.9GB"},
    "large-v3": {"nome": "Large-v3", "descricao": "Vers√£o 3 do modelo Large, precis√£o avan√ßada", "tamanho": "2.1GB"},
    "turbo": {"nome": "Turbo", "descricao": "Modelo otimizado de alta performance", "tamanho": "2.3GB"}
}

modelo_escolhido = st.sidebar.selectbox(
    "Modelo:",
    options=list(opcoes_modelos.keys()),
    index=2,  # Corresponde ao "small"
    format_func=lambda x: opcoes_modelos[x]["nome"],
    disabled="audio_processado" in st.session_state
)

st.sidebar.text(f"Tamanho do modelo escolhido: {opcoes_modelos[modelo_escolhido]['tamanho']}")

# üåê Idioma
st.sidebar.subheader("üåç Idioma do √°udio")
opcoes_idiomas = {
    "pt": "Portugu√™s (Brasil)",
    "en": "Ingl√™s",
    "es": "Espanhol",
    "fr": "Franc√™s",
    "de": "Alem√£o",
    "auto": "üåê Detectar automaticamente"
}
idioma_escolhido_label = st.sidebar.selectbox(
    "Idioma:", list(opcoes_idiomas.values()), index=0,
    disabled="audio_processado" in st.session_state
)
idioma_escolhido = list(opcoes_idiomas.keys())[list(opcoes_idiomas.values()).index(idioma_escolhido_label)]

# ‚öôÔ∏è Op√ß√µes Avan√ßadas
st.sidebar.subheader("‚öôÔ∏è Op√ß√µes Avan√ßadas")
if "audio_processado" not in st.session_state:
    st.session_state['habilitar_diarizacao'] = st.sidebar.checkbox(
        "üë• Reconhecimento de locutor (Diariza√ß√£o)", 
        value=st.session_state['habilitar_diarizacao']
    )
    st.session_state['chunk_processing'] = st.sidebar.checkbox(
        "üß© Processamento em chunks", 
        value=st.session_state['chunk_processing']
    )
    st.session_state['auto_cleanup'] = st.sidebar.checkbox(
        "üßπ Limpeza autom√°tica de mem√≥ria", 
        value=st.session_state['auto_cleanup']
    )
else:
    st.sidebar.write("üë• Reconhecimento de locutor: " + 
                     (f"<span style='color:green'>Habilitado</span>" if st.session_state['habilitar_diarizacao'] else 
                      f"<span style='color:red'>Desabilitado</span>"), 
                     unsafe_allow_html=True)
    st.sidebar.write("üß© Processamento em chunks: " + 
                     (f"<span style='color:green'>Habilitado</span>" if st.session_state['chunk_processing'] else 
                      f"<span style='color:red'>Desabilitado</span>"), 
                     unsafe_allow_html=True)
    st.sidebar.write("üßπ Limpeza autom√°tica de mem√≥ria: " + 
                     (f"<span style='color:green'>Habilitada</span>" if st.session_state['auto_cleanup'] else 
                      f"<span style='color:red'>Desabilitada</span>"), 
                     unsafe_allow_html=True)

st.sidebar.markdown(
    f"üíª **Detec√ß√£o autom√°tica de hardware**\n\n"
    f"- Threads de processamento: {threads}\n"
    f"- Mem√≥ria RAM: {mem_total_gb:.1f} GB\n"
    f"- Espa√ßo em disco livre: {free_gb:.1f} GB de {total_gb:.1f} GB"
)

# üéôÔ∏è P√°gina principal
st.header("üéôÔ∏è SPAV - Transcri√ß√£o de √Åudio", divider=True)
st.write("Transcri√ß√£o e reconhecimento de voz.")
load_dotenv()
HUGGINGFACE_TOKEN = os.getenv("HUGGINGFACE_TOKEN")
if st.session_state['habilitar_diarizacao'] and not HUGGINGFACE_TOKEN:
    st.error("‚ö†Ô∏è Token do HuggingFace n√£o encontrado. Defina no arquivo `.env` ou desabilite a diariza√ß√£o")
    st.stop()

# üì§ Upload do √°udio
st.header("üì§ Upload do Arquivo")
audio_file = st.file_uploader(
    "Selecione um arquivo de √°udio", type=["mp3", "wav", "m4a", "flac"],
    help="Formatos suportados: MP3, WAV, M4A, FLAC"
)

# üîÑ Bot√£o de reiniciar sempre vis√≠vel
col1, col2, col3 = st.columns(3)
with col1:
    if st.button("üîÑ Reiniciar Aplica√ß√£o", type="primary"):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()
with col2:
    st.write("")  # Espa√ßo reservado
with col3:
    st.write("")  # Espa√ßo reservado

if audio_file:
    try:
        file_size_mb = len(audio_file.read()) / (1024 * 1024)
        audio_file.seek(0)
        if file_size_mb > 100:
            st.warning("‚ö†Ô∏è Arquivo √© grande. O processamento ser√° lento.")
    except Exception:
        st.info("‚úÖ Arquivo carregado com sucesso")
    if "audio_processado" not in st.session_state or st.session_state["audio_processado"] != audio_file.name:
        for key in ["tabela_falas", "nome_base", "modelo_escolhido", "doc_word", "csv_data", "srt_data"]:
            st.session_state.pop(key, None)
        st.session_state["audio_processado"] = audio_file.name

# üé¨ Processamento do √°udio
if audio_file:
    # Remova as colunas anteriores
    if st.button("üöÄ Iniciar Transcri√ß√£o", type="secondary"):
        audio_path = os.path.join(os.getcwd(), f"temp_{audio_file.name}")
        try:
            with open(audio_path, "wb") as f:
                f.write(audio_file.read())
            
            # Use st.empty() com uma largura total
            st.header("üîÑ Progresso da Transcri√ß√£o")
            
            # Crie um cont√™iner de largura total
            progress_container = st.container()
            with progress_container:
                # Use st.empty() de forma semelhante ao seu c√≥digo original
                progresso_placeholder = st.empty()
                status_placeholder = st.empty()
                
                # Configurar progresso para ocupar toda a largura
                progresso = progresso_placeholder.progress(0, text="")
                status = status_placeholder
                
                atualizar_progresso(progresso, status, "ü§ñ Carregando modelo Whisper", 5)
                modelo = whisper.load_model(modelo_escolhido)
                atualizar_progresso(progresso, status, "üéôÔ∏è Transcrevendo √°udio", 15)
                progress_queue = queue.Queue()
                if st.session_state['chunk_processing']:
                    processar_audio_chunk(modelo, audio_path, idioma_escolhido, progress_queue)
                    result_type, resultado = progress_queue.get_nowait()
                    if result_type == "erro":
                        raise Exception(resultado)
                else:
                    resultado = modelo.transcribe(audio_path, language=None if idioma_escolhido=="auto" else idioma_escolhido)
                atualizar_progresso(progresso, status, "‚úÖ Transcri√ß√£o conclu√≠da", 50)
                del modelo
                
                # üîä Diariza√ß√£o condicional
                diarization = None
                if st.session_state['habilitar_diarizacao']:
                    atualizar_progresso(progresso, status, "üë• Inicializando diariza√ß√£o", 55)
                    processar_diarizacao(audio_path, HUGGINGFACE_TOKEN, progress_queue)
                    result_type, diarization = progress_queue.get_nowait()
                    if result_type == "erro":
                        raise Exception(resultado)
                    atualizar_progresso(progresso, status, "‚úÖ Diariza√ß√£o conclu√≠da", 75)
                else:
                    atualizar_progresso(progresso, status, "‚è© Diariza√ß√£o desabilitada", 75)
                
                # üìù Processar segmentos
                falas = []
                mapa_locutores = {}
                contador_locutor = 1
                total_segmentos = len(resultado["segments"])
                for i, segmento in enumerate(resultado["segments"]):
                    start = segmento["start"]
                    end = segmento["end"]
                    texto = f'"{segmento["text"].strip()}"'
                    speaker = "Locutor 1"  # Valor padr√£o quando diariza√ß√£o est√° desabilitada
                    
                    if st.session_state['habilitar_diarizacao'] and diarization:
                        speaker = "Desconhecido"
                        for turno in diarization.itertracks(yield_label=True):
                            seg_dia = turno[0]
                            locutor_original = turno[-1]
                            if seg_dia.start <= start <= seg_dia.end:
                                speaker = locutor_original
                                break
                        if speaker not in mapa_locutores and speaker != "Desconhecido":
                            mapa_locutores[speaker] = f"Locutor {contador_locutor}"
                            contador_locutor += 1
                        speaker = mapa_locutores.get(speaker, speaker)
                    
                    falas.append({
                        "tempo": f"{formatar_tempo(start)} - {formatar_tempo(end)}",
                        "locutor": speaker,
                        "texto": texto
                    })
                    if i % max(1, total_segmentos // 10) == 0:
                        progress_val = 80 + int(10*(i+1)/total_segmentos)
                        atualizar_progresso(progresso, status, "üß© Processando segmentos", progress_val)
                
                # üìÑ Gerar documentos
                doc = Document()
                doc.add_heading(f'Tabela 1 - Transcri√ß√£o do √Åudio "{audio_file.name}".', level=1)
                tabela = doc.add_table(rows=1, cols=3)
                tabela.style = 'Table Grid'
                hdr_cells = tabela.rows[0].cells
                hdr_cells[0].text = 'Tempo'
                hdr_cells[1].text = 'Locutor'
                hdr_cells[2].text = 'Transcri√ß√£o'
                for fala in falas:
                    row_cells = tabela.add_row().cells
                    row_cells[0].text = fala["tempo"]
                    row_cells[1].text = fala["locutor"]
                    row_cells[2].text = fala["texto"]
                doc_stream = BytesIO()
                doc.save(doc_stream)
                doc_stream.seek(0)
                st.session_state["doc_word"] = doc_stream
                st.session_state["tabela_falas"] = pd.DataFrame([{"Tempo": f["tempo"], "Locutor": f["locutor"], "Transcri√ß√£o": f["texto"]} for f in falas])
                st.session_state["tabela_falas"].index += 1
                st.session_state["csv_data"] = st.session_state["tabela_falas"].to_csv(index=False)
                
                # üé¨ Gerar arquivo SRT
                srt_content = criar_srt(falas)
                st.session_state["srt_data"] = srt_content
                
                atualizar_progresso(progresso, status, "‚úÖ Processamento conclu√≠do!", 100)

        except Exception as e:
            st.error(f"‚ö†Ô∏è Erro durante o processamento:")
            st.code(str(e))
            st.expander("üêû Detalhes t√©cnicos").code(traceback.format_exc())
        finally:
            if os.path.exists(audio_path):
                os.remove(audio_path)

# üìä Exibir resultados
if "tabela_falas" in st.session_state:
    col_btn1, col_btn2, col_btn3, col_btn4 = st.columns(4)
    with col_btn1:
        st.download_button(
            label="üìÑ Baixar Word",
            data=st.session_state["doc_word"],
            file_name=f"{st.session_state['audio_processado'].split('.')[0]}-{modelo_escolhido}.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
    with col_btn2:
        st.download_button(
            label="üìä Baixar CSV",
            data=st.session_state["csv_data"],
            file_name=f"{st.session_state['audio_processado'].split('.')[0]}-{modelo_escolhido}.csv",
            mime="text/csv"
        )
    with col_btn3:
        st.download_button(
            label="üìù Baixar SRT",
            data=st.session_state["srt_data"],
            file_name=f"{st.session_state['audio_processado'].split('.')[0]}-{modelo_escolhido}.srt",
            mime="text/plain"
        )
    with col_btn4:
        if st.button("üßπ Limpar Resultados", type="primary"):
            for key in ["tabela_falas", "doc_word", "csv_data", "srt_data", "audio_processado"]:
                st.session_state.pop(key, None)
            st.rerun()
    
    st.subheader("üéº Transcri√ß√£o Completa")
    st.dataframe(st.session_state["tabela_falas"], use_container_width=True, height=400)
    with st.expander("üìà Estat√≠sticas Detalhadas"):
        df = st.session_state["tabela_falas"]
        col_stat1, col_stat2 = st.columns(2)
        with col_stat1:
            st.metric("Total de Falas", len(df))
            st.metric("Locutores √önicos", df['Locutor'].nunique())
        with col_stat2:
            distribuicao = df['Locutor'].value_counts()
            st.write("**Distribui√ß√£o de Falas por Locutor:**")
            for locutor, count in distribuicao.items():
                st.write(f"‚Ä¢ {locutor}: {count} falas")

# Executa a aplica√ß√£o
if __name__ == "__main__":
    st.write("")  # Necess√°rio para inicializa√ß√£o do Streamlit
